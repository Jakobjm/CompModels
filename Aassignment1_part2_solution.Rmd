---
title: "Assignment1_part2"
author: "Jakob MÃ¸rup"
date: "18/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(pacman)
p_load(tidyverse, rethinking, brms)
```



```{r}
#defining the grid of 10000 possible parameter values, more is always better right? and when it's a low computational effort like here, 10000 seems reasonable.
dens = 1e4
p_grid = seq(from=0, to=1, length.out = dens)
prior_norm = rnorm(dens,mean = 0.8, sd = 0.2)

```


```{r}
#quickly calculating the old posteriors to use as priors fir the u-pdating

likelihood_riccardo = dbinom(3 ,size = 6,prob = p_grid )
likelihood_kristian = dbinom(2 ,size = 2,prob = p_grid )
likelihood_daina = dbinom(160 ,size = 198,prob = p_grid )
likelihood_mikkel = dbinom(66 ,size = 132,prob = p_grid )

unstd_posterior_norm_riccardo = likelihood_riccardo * prior_norm
unstd_posterior_norm_kristian = likelihood_kristian * prior_norm
unstd_posterior_norm_daina = likelihood_daina * prior_norm
unstd_posterior_norm_mikkel = likelihood_mikkel * prior_norm

#standardising the posterior for each teacher
posterior_norm_riccardo = unstd_posterior_norm_riccardo/sum(unstd_posterior_norm_riccardo)
posterior_norm_kristian = unstd_posterior_norm_kristian/sum(unstd_posterior_norm_kristian)
posterior_norm_daina = unstd_posterior_norm_daina/sum(unstd_posterior_norm_daina)
posterior_norm_mikkel = unstd_posterior_norm_mikkel/sum(unstd_posterior_norm_mikkel)

```


```{r}
likelihood_riccardo_3 = dbinom(9 ,size = 10,prob = p_grid )
likelihood_kristian_3 = dbinom(8 ,size = 12,prob = p_grid )
likelihood_daina_3 = dbinom(148 ,size = 172,prob = p_grid )
likelihood_mikkel_3 = dbinom(34 ,size = 65,prob = p_grid )



unstd_posterior_norm_riccardo_3 = likelihood_riccardo_3 * posterior_norm_riccardo
unstd_posterior_norm_kristian_3 = likelihood_kristian_3 * posterior_norm_kristian
unstd_posterior_norm_daina_3 = likelihood_daina_3 * posterior_norm_daina
unstd_posterior_norm_mikkel_3 = likelihood_mikkel_3 * posterior_norm_mikkel

#standardising the posterior for each teacher
posterior_norm_riccardo_3 = unstd_posterior_norm_riccardo_3/sum(unstd_posterior_norm_riccardo_3)
posterior_norm_kristian_3 = unstd_posterior_norm_kristian_3/sum(unstd_posterior_norm_kristian_3)
posterior_norm_daina_3 = unstd_posterior_norm_daina_3/sum(unstd_posterior_norm_daina_3)
posterior_norm_mikkel_3 = unstd_posterior_norm_mikkel_3/sum(unstd_posterior_norm_mikkel_3)

#making a dataframe of grid, posterior, prior_unif, and likelihood for each teacher
df_norm_prior_riccardo_3 = data.frame(grid = p_grid, posterior = posterior_norm_riccardo_3, prior = posterior_norm_riccardo, likelihood = likelihood_riccardo_3)
df_norm_prior_kristian_3 = data.frame(grid = p_grid, posterior = posterior_norm_kristian_3, prior = posterior_norm_kristian, likelihood = likelihood_kristian_3)
df_norm_prior_daina_3 = data.frame(grid = p_grid, posterior = posterior_norm_daina_3, prior = posterior_norm_daina, likelihood = likelihood_daina_3)
df_norm_prior_mikkel_3 = data.frame(grid = p_grid, posterior = posterior_norm_mikkel_3, prior = posterior_norm_mikkel, likelihood = likelihood_mikkel_3)

#plotting the posterior for each teacher
plot_ric_post_norm_3 = ggplot(df_norm_prior_riccardo_3, aes(grid,posterior)) +  geom_point(alpha=0.3, colour = "blue") +geom_line(alpha=0.3, colour = "blue")+geom_point(aes(grid,prior), alpha=0.3, colour = "red") +geom_line(aes(grid,prior),alpha=0.3, colour = "red")+theme_classic() + xlab("Knowledge of CogSci")+ ylab("posterior probability")
plot_ric_post_norm_3
plot_kri_post_norm_3 = ggplot(df_norm_prior_kristian_3, aes(grid,posterior)) +  geom_point(alpha=0.3, colour = "blue") +geom_line(alpha=0.3, colour = "blue")+geom_point(aes(grid,prior), alpha=0.3, colour = "red") +geom_line(aes(grid,prior),alpha=0.3, colour = "red")+theme_classic() + xlab("Knowledge of CogSci")+ ylab("posterior probability")
plot_kri_post_norm_3
plot_dai_post_norm_3 = ggplot(df_norm_prior_daina_3, aes(grid,posterior)) +  geom_point(alpha=0.3, colour = "blue") +geom_line(alpha=0.3, colour = "blue")+geom_point(aes(grid,prior), alpha=0.3, colour = "red") +geom_line(aes(grid,prior),alpha=0.3, colour = "red")+theme_classic() + xlab("Knowledge of CogSci")+ ylab("posterior probability")
plot_dai_post_norm_3
plot_mik_post_norm_3 = ggplot(df_norm_prior_mikkel_3, aes(grid,posterior)) +  geom_point(alpha=0.3, colour = "blue") +geom_line(alpha=0.3, colour = "blue")+geom_point(aes(grid,prior), alpha=0.3, colour = "red") +geom_line(aes(grid,prior),alpha=0.3, colour = "red")+theme_classic() + xlab("Knowledge of CogSci")+ ylab("posterior probability")
plot_mik_post_norm_3




samples_riccardo_3 = sample(p_grid, prob = posterior_norm_riccardo_3, size = 1e4, replace = T)
samples_kristian_3 = sample(p_grid, prob = posterior_norm_kristian_3, size = 1e4, replace = T)
samples_daina_3 = sample(p_grid, prob = posterior_norm_daina_3, size = 1e4, replace = T)
samples_mikkel_3 = sample(p_grid, prob = posterior_norm_mikkel_3, size = 1e4, replace = T)

# calculating the ratio of answers above chance level for riccardo, using samples from the posterior, while I could use the actual posterior distribution,
prob_above_chance_riccardo_3 = sum(samples_riccardo_3)/1e4 
prob_above_chance_kristian_3 = sum(samples_kristian_3)/1e4
prob_above_chance_daina_3 = sum(samples_daina_3)/1e4
prob_above_chance_mikkel_3 = sum(samples_mikkel_3)/1e4

prob_above_chance_riccardo_3 # 0.72
prob_above_chance_kristian_3 # 0.68
prob_above_chance_daina_3 # 0.83
prob_above_chance_mikkel_3 # 0.50

```


```{r}
```